{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKpb8Iu9ptGOHVZKuBUmuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohan-th/Levothyscan/blob/master/script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C57UUXCj80C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import threading\n",
        "import timeit\n",
        "import time\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "# Parametre\n",
        "search = \"levothyrox\"\n",
        "rubrique = \"18*sante\"\n",
        "debug = False\n",
        "save_tmp_out = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67Lso01f8AaX",
        "colab_type": "text"
      },
      "source": [
        "# Tools\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kjoel1J57M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GetAllPages_topic_Thread(threading.Thread):\n",
        "\n",
        "    def __init__(self, url, page, nb_page, sujet):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.url = url\n",
        "        self.page = page\n",
        "        self.nb_page = nb_page\n",
        "        self.sujet = sujet\n",
        "\n",
        "    def run(self):\n",
        "        global all_msg\n",
        "        if debug:\n",
        "          print(\"[Ouverture URL de \\\"\" + self.sujet + \"\\\" page \" + str(page) + \"] : \" + str(url))\n",
        "        try:\n",
        "          with urllib.request.urlopen(url) as response:\n",
        "            html = response.read().decode('utf-8')\n",
        "        except SocketError as e:\n",
        "          if e.errno == errno.ECONNRESET:\n",
        "            print(\"-------> thread request error\")\n",
        "            time.sleep(30)\n",
        "            return\n",
        "          else:\n",
        "            print(\"-!-!-!-> thread request error\")\n",
        "            return\n",
        "       \n",
        "        only_messages = re.search('<div id=\"topic\" >(.*?)<div class=\"bottom_action_topic_menu\">', html, re.MULTILINE | re.DOTALL).group(1)\n",
        "        messages_page = re.findall('class=\"md-topic_post(.*?)/table>', only_messages, re.MULTILINE | re.DOTALL)\n",
        "\n",
        "        for message in messages_page:\n",
        "          if re.match('.*data-id_user.*', message, re.DOTALL):\n",
        "              user = re.search('data-id_user.*?>(.+?)<', message).group(1)\n",
        "          elif re.match('.*itemprop=\"name\"', message, re.DOTALL):\n",
        "              try:\n",
        "                user = re.search('itemprop=\"name\".+?>(.+?)<', message).group(1)\n",
        "              except:\n",
        "                print(html)\n",
        "          elif re.match('.*Profil supprimé.*', message, re.DOTALL):\n",
        "              user = \"Profil supprimé\"\n",
        "          else:\n",
        "              user = \"[ERROR_Encodage_user_unknown]\"\n",
        "          date = re.search('Posté le ([0-9/]+)', message).group(1)\n",
        "          if re.match('.*itemprop=\"citation\".*', message, re.DOTALL):\n",
        "            message = re.sub('itemprop=\"citation\".+?</span></span>', '', message, re.MULTILINE | re.DOTALL)\n",
        "          text = re.search('itemprop=\"text\" hidden>(.*?)</span><div>', message, re.MULTILINE | re.DOTALL).group(1)\n",
        "          text = clean_message(text)\n",
        "          all_msg = all_msg.append({'date':date, 'user':user, 'text':text, 'url':url}, ignore_index=True)\n",
        "\n",
        "        if debug:\n",
        "          print(\"[\" + str(len(messages_page)) + \" new msg sur \\\"\" + self.sujet + \"\\\" de la page \" + str(self.page) + \" sur \" + self.nb_page + \"]\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxhNxnm75w0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def clean_message(msg):\n",
        "    msg = re.sub('&#039;', '\\'', msg)#apostrophe\n",
        "    msg = re.sub(';', ' ', msg)  # Pour un decoupage correct sur excel\n",
        "    msg = re.sub('[>\\r\\n]+', ' ', msg) #Saut de ligne\n",
        "    msg = re.sub(':\\w+:', ' ', msg) #les smiley :happy:\n",
        "    msg = re.sub('http\\://.+?\\.html', '', msg) #les liens copi\n",
        "    msg = re.sub('<img.*?/>', ' ', msg)  #suppr les images\n",
        "    msg = re.sub('<br.*?>', ' ', msg) #suppr les balise br\n",
        "    msg = re.sub('<a (.*?)</a>', ' ', msg) #suppr les liens externe\n",
        "    msg = re.sub('</?span.*?>', ' ', msg)\n",
        "    msg = re.sub('</?table.*?>', ' ', msg)\n",
        "    msg = re.sub('</?[a-z][a-z]?>', ' ', msg) #</i> <lu> et bien d'autre\n",
        "    msg = re.sub('&[a-z#0-9]{1,4};', ' ', msg) #&#034; &nbsp; &euro; &gt; &lt;\n",
        "    msg = re.sub('\\[#[0-9]+ size=[0-9]+\\]', ' ', msg)\n",
        "    msg = re.sub('</?strong>', ' ', msg)\n",
        "    msg = re.sub('</?div>?', ' ', msg)\n",
        "\n",
        "    #Decommenter les lignes suivantes pour clean plus exhaustif\n",
        "    #while re.search(\" ['\\w^.><?!)(/@*_&%:+\\-]{0,4} \", msg):\n",
        "    #    msg = re.sub(\" ['\\w^.><?!)(/@*_&%:;+\\-]{0,4} \", ' ', msg)\n",
        "    #msg = unicodedata.normalize('NFD', msg).encode('ascii', 'ignore')  # suppr les accents\n",
        "    return(msg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_uLH85v52JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_nbr_page(html):\n",
        "    list_pages = re.search('pagination_main_visible(.+?)/div', html).group(1)\n",
        "    if re.match(r\".*href.*\", list_pages):\n",
        "        return(re.findall(\"\\\">([0-9]+)<\", html)[-1])\n",
        "    else:\n",
        "        return(\"1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoFGDRLe8T4U",
        "colab_type": "text"
      },
      "source": [
        "# Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHcJBQ4q88rr",
        "colab_type": "text"
      },
      "source": [
        "Récupéation des adresses url de l'ensemble des topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IQoqohC6qMm",
        "colab_type": "code",
        "outputId": "e496c099-3a10-4d70-97f0-066f47df5107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "print(\"Recherche de <\"+search+\"> dans la rubrique <\"+rubrique+\">\")\n",
        "if debug:\n",
        "    print('http://forum.doctissimo.fr/search_result.php?post_cat_list='+rubrique+'&search='+search+'&resSearch=250')\n",
        "with urllib.request.urlopen('http://forum.doctissimo.fr/search_result.php?post_cat_list='+rubrique+'&search='+search+'&resSearch=250') as response:\n",
        "  html = response.read().decode('utf-8')\n",
        "if re.match(r\".*aucune réponse n'a été trouvée.*\", html, re.MULTILINE|re.DOTALL):\n",
        "    print(\"La recherche de <\"+search+\"> dans la rubrique <\"+rubrique+\"> donne aucun résultat\")\n",
        "    sys.exit()\n",
        "nb_page_topic = get_nbr_page(html)\n",
        "\n",
        "print(nb_page_topic+\" page(s) de 250 topics sur le sujet <\"+search+\"> dans la rubrique <\"+rubrique+\">\")\n",
        "\n",
        "all_topics_url = []\n",
        "page = 1\n",
        "if debug:\n",
        "    nb_page_topic = \"1\"\n",
        "while page <= int(nb_page_topic):\n",
        "    print(\"telechargement de page \" + str(page) + \" sur \" + nb_page_topic)\n",
        "    if debug:\n",
        "        print('http://forum.doctissimo.fr/search_result.php?post_cat_list='+rubrique+'&search='+search+'&resSearch=250&page='+str(page))\n",
        "    with urllib.request.urlopen('http://forum.doctissimo.fr/search_result.php?post_cat_list='+rubrique+'&search='+search+'&resSearch=250&page='+str(page)) as response:\n",
        "        html = response.read().decode('utf-8')\n",
        "    topics = re.findall(r\"</?t.*?sujet ligne_booleen(.+?)</tr>\", html, re.MULTILINE | re.DOTALL)\n",
        "    for topic in topics:\n",
        "        if debug:\n",
        "            print(re.search(r\"href=\\\"(.+?)\\\"\", topic).group(1))\n",
        "        all_topics_url.append(re.search(r\"href=\\\"(.+?)\\\"\", topic).group(1))\n",
        "    page += 1\n",
        "print(\"nb total de topic = \" + str(len(all_topics_url)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recherche de <levothyrox> dans la rubrique <18*sante>\n",
            "32 page(s) de 250 topics sur le sujet <levothyrox> dans la rubrique <18*sante>\n",
            "telechargement de page 1 sur 32\n",
            "telechargement de page 2 sur 32\n",
            "telechargement de page 3 sur 32\n",
            "telechargement de page 4 sur 32\n",
            "telechargement de page 5 sur 32\n",
            "telechargement de page 6 sur 32\n",
            "telechargement de page 7 sur 32\n",
            "telechargement de page 8 sur 32\n",
            "telechargement de page 9 sur 32\n",
            "telechargement de page 10 sur 32\n",
            "telechargement de page 11 sur 32\n",
            "telechargement de page 12 sur 32\n",
            "telechargement de page 13 sur 32\n",
            "telechargement de page 14 sur 32\n",
            "telechargement de page 15 sur 32\n",
            "telechargement de page 16 sur 32\n",
            "telechargement de page 17 sur 32\n",
            "telechargement de page 18 sur 32\n",
            "telechargement de page 19 sur 32\n",
            "telechargement de page 20 sur 32\n",
            "telechargement de page 21 sur 32\n",
            "telechargement de page 22 sur 32\n",
            "telechargement de page 23 sur 32\n",
            "telechargement de page 24 sur 32\n",
            "telechargement de page 25 sur 32\n",
            "telechargement de page 26 sur 32\n",
            "telechargement de page 27 sur 32\n",
            "telechargement de page 28 sur 32\n",
            "telechargement de page 29 sur 32\n",
            "telechargement de page 30 sur 32\n",
            "telechargement de page 31 sur 32\n",
            "telechargement de page 32 sur 32\n",
            "nb total de topic = 7735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAWd21t19_aS",
        "colab_type": "text"
      },
      "source": [
        "Récupération des adresses url des pages **de chaque topic** et téléchargement de chaque page **dans un thread séparé**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q7Kga-kxmYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f9a74a6-e84c-46b3-c518-0452cde36203"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "\n",
        "all_msg = pd.DataFrame(columns=['date','user', 'text', 'url'])\n",
        "threadList = []\n",
        "nb_topic = 0\n",
        "\n",
        "for url in all_topics_url:\n",
        "    if debug:\n",
        "        time.sleep(2)\n",
        "\n",
        "    try:\n",
        "      with urllib.request.urlopen(url) as response:\n",
        "        html = response.read().decode('utf-8')\n",
        "    except SocketError as e:\n",
        "      if e.errno != errno.ECONNRESET:\n",
        "        print(\"-------> urlib request error\")\n",
        "        time.sleep(30)\n",
        "        continue\n",
        "      else:\n",
        "        print(\"-!-!-!-> urlib request error\")\n",
        "        continue\n",
        "\n",
        "    sujet_topic = re.search(\"forum.doctissimo.fr/sante/.+/(.*?)sujet_\", url).group(1)\n",
        "    nb_page_topic = get_nbr_page(html)\n",
        "    if debug:\n",
        "        print(\"topic \\\"\"+sujet_topic+\"\\\" avec \"+str(nb_page_topic)+\" page(s)\")\n",
        "    \n",
        "    page = 1\n",
        "    while page <= int(nb_page_topic):\n",
        "        clean_url = re.search(r\"(.*)_\", url).group(1)\n",
        "        newthread = GetAllPages_topic_Thread(clean_url + \"_\" + str(page) + \".htm\", page, nb_page_topic, sujet_topic)\n",
        "        newthread.start()\n",
        "        time.sleep(0.1)\n",
        "        threadList.append(newthread)\n",
        "        page += 1\n",
        "\n",
        "    if (nb_topic % 100 == 0):\n",
        "      print(str(nb_topic) + \" topics extrait sur \" + str(len(all_topics_url)) + \". Messages récoltés : \" + str(len(all_msg)))\n",
        "    \n",
        "    if len(all_msg) > 1000 and save_tmp_out == True:\n",
        "        all_msg.to_csv(\"tmp_out.csv\", sep=';', encoding='utf-8', index=False)\n",
        "        print(\"Fichier temporaire save --> tmp_out.csv\")\n",
        "        save_tmp_out = False\n",
        "\n",
        "    nb_topic += 1\n",
        "\n",
        "print(\"Attente des threats\")\n",
        "for curThread in threadList :\n",
        "    curThread.join()\n",
        "\n",
        "all_msg.to_csv(\"out.csv\", sep=';', encoding='utf-8', index=False)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "m, s = divmod(stop - start, 60)\n",
        "h, m = divmod(m, 60)\n",
        "print(str(len(all_msg)) + \" messages total récoltés en %dh %02dmin et %02ds\" % (h, m, s))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 topics extrait sur 7735. Messages récoltés : 0\n",
            "Fichier temporaire save --> tmp_out.csv\n",
            "100 topics extrait sur 7735. Messages récoltés : 1462\n",
            "200 topics extrait sur 7735. Messages récoltés : 2651\n",
            "300 topics extrait sur 7735. Messages récoltés : 4087\n",
            "400 topics extrait sur 7735. Messages récoltés : 5075\n",
            "500 topics extrait sur 7735. Messages récoltés : 6556\n",
            "600 topics extrait sur 7735. Messages récoltés : 7447\n",
            "700 topics extrait sur 7735. Messages récoltés : 8429\n",
            "800 topics extrait sur 7735. Messages récoltés : 9505\n",
            "900 topics extrait sur 7735. Messages récoltés : 11402\n",
            "1000 topics extrait sur 7735. Messages récoltés : 13229\n",
            "1100 topics extrait sur 7735. Messages récoltés : 15303\n",
            "1200 topics extrait sur 7735. Messages récoltés : 16771\n",
            "1300 topics extrait sur 7735. Messages récoltés : 17981\n",
            "1400 topics extrait sur 7735. Messages récoltés : 19088\n",
            "1500 topics extrait sur 7735. Messages récoltés : 20214\n",
            "1600 topics extrait sur 7735. Messages récoltés : 21427\n",
            "1700 topics extrait sur 7735. Messages récoltés : 22604\n",
            "1800 topics extrait sur 7735. Messages récoltés : 24017\n",
            "1900 topics extrait sur 7735. Messages récoltés : 25093\n",
            "2000 topics extrait sur 7735. Messages récoltés : 25929\n",
            "2100 topics extrait sur 7735. Messages récoltés : 27536\n",
            "2200 topics extrait sur 7735. Messages récoltés : 28889\n",
            "2300 topics extrait sur 7735. Messages récoltés : 30058\n",
            "2400 topics extrait sur 7735. Messages récoltés : 31124\n",
            "2500 topics extrait sur 7735. Messages récoltés : 32264\n",
            "2600 topics extrait sur 7735. Messages récoltés : 33640\n",
            "2700 topics extrait sur 7735. Messages récoltés : 34938\n",
            "2800 topics extrait sur 7735. Messages récoltés : 36433\n",
            "2900 topics extrait sur 7735. Messages récoltés : 38171\n",
            "3000 topics extrait sur 7735. Messages récoltés : 39570\n",
            "3100 topics extrait sur 7735. Messages récoltés : 40670\n",
            "3200 topics extrait sur 7735. Messages récoltés : 41785\n",
            "3300 topics extrait sur 7735. Messages récoltés : 42622\n",
            "3400 topics extrait sur 7735. Messages récoltés : 43689\n",
            "3500 topics extrait sur 7735. Messages récoltés : 45249\n",
            "3600 topics extrait sur 7735. Messages récoltés : 46990\n",
            "3700 topics extrait sur 7735. Messages récoltés : 48537\n",
            "3800 topics extrait sur 7735. Messages récoltés : 49843\n",
            "3900 topics extrait sur 7735. Messages récoltés : 51241\n",
            "4000 topics extrait sur 7735. Messages récoltés : 52651\n",
            "4100 topics extrait sur 7735. Messages récoltés : 53954\n",
            "4200 topics extrait sur 7735. Messages récoltés : 55258\n",
            "4300 topics extrait sur 7735. Messages récoltés : 56796\n",
            "4400 topics extrait sur 7735. Messages récoltés : 57842\n",
            "4500 topics extrait sur 7735. Messages récoltés : 59095\n",
            "4600 topics extrait sur 7735. Messages récoltés : 60200\n",
            "4700 topics extrait sur 7735. Messages récoltés : 61790\n",
            "4800 topics extrait sur 7735. Messages récoltés : 62941\n",
            "4900 topics extrait sur 7735. Messages récoltés : 64084\n",
            "5000 topics extrait sur 7735. Messages récoltés : 65467\n",
            "5100 topics extrait sur 7735. Messages récoltés : 66700\n",
            "5200 topics extrait sur 7735. Messages récoltés : 68005\n",
            "5300 topics extrait sur 7735. Messages récoltés : 69285\n",
            "5400 topics extrait sur 7735. Messages récoltés : 70583\n",
            "5500 topics extrait sur 7735. Messages récoltés : 71763\n",
            "5600 topics extrait sur 7735. Messages récoltés : 73356\n",
            "5700 topics extrait sur 7735. Messages récoltés : 74642\n",
            "5800 topics extrait sur 7735. Messages récoltés : 76266\n",
            "5900 topics extrait sur 7735. Messages récoltés : 77542\n",
            "6000 topics extrait sur 7735. Messages récoltés : 78625\n",
            "6100 topics extrait sur 7735. Messages récoltés : 79843\n",
            "6200 topics extrait sur 7735. Messages récoltés : 81060\n",
            "6300 topics extrait sur 7735. Messages récoltés : 82138\n",
            "6400 topics extrait sur 7735. Messages récoltés : 83361\n",
            "6500 topics extrait sur 7735. Messages récoltés : 85088\n",
            "6600 topics extrait sur 7735. Messages récoltés : 86309\n",
            "6700 topics extrait sur 7735. Messages récoltés : 87530\n",
            "6800 topics extrait sur 7735. Messages récoltés : 88868\n",
            "6900 topics extrait sur 7735. Messages récoltés : 89974\n",
            "7000 topics extrait sur 7735. Messages récoltés : 91333\n",
            "7100 topics extrait sur 7735. Messages récoltés : 92864\n",
            "7200 topics extrait sur 7735. Messages récoltés : 94401\n",
            "7300 topics extrait sur 7735. Messages récoltés : 95693\n",
            "7400 topics extrait sur 7735. Messages récoltés : 96641\n",
            "7500 topics extrait sur 7735. Messages récoltés : 97607\n",
            "7600 topics extrait sur 7735. Messages récoltés : 98300\n",
            "7700 topics extrait sur 7735. Messages récoltés : 98937\n",
            "Attente des threats\n",
            "99168 messages total récoltés en 1h 18min et 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5dsMC-Ys-AB",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBwqpHyDsVuH",
        "colab_type": "text"
      },
      "source": [
        "Pour vérifier que les regex sont ok pour extraire :\n",
        "\n",
        "*   user\n",
        "*   date\n",
        "*   text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ6iUh1r2RIm",
        "colab_type": "code",
        "outputId": "8838a7f2-0c1c-4c8a-f540-ad886a838bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "from google.colab import files\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "url = \"http://forum.doctissimo.fr/sante/arthrose-os/maigrir-sujet_149370_1.htm\" # profil supprimé + citation normol\n",
        "url = \"http://forum.doctissimo.fr/sante/regles-problemes-gynecologiques/retart-regles-sujet_222033_1.htm\" # encodage citation différent\n",
        "url = \"http://forum.doctissimo.fr/sante/thyroide-problemes-endocrinologiques/endocrinologue-belgique-sujet_160644_1.htm\" # encodage user avec space authorisé (Susanne in F)\n",
        "url = \"http://forum.doctissimo.fr/sante/thyroide-problemes-endocrinologiques/supportez-thyroxine-sanofi-sujet_171008_1.htm\" #avec hidden dans code devant user name\n",
        "url = \"http://forum.doctissimo.fr/sante/autres-drogues-dependances/alcool-cocaine-sujet_183131_2.htm\"\n",
        "\n",
        "df = pd.DataFrame(columns=['date','user', 'text', 'url'])\n",
        "\n",
        "try:\n",
        "    with urllib.request.urlopen(url) as rep:\n",
        "        html = rep.read().decode('utf-8')\n",
        "except (http.client.IncompleteRead) as e:\n",
        "    html = e.partial.decode('utf-8')\n",
        "#print(html)\n",
        "\n",
        "#with open(\"1_all_website.html\", \"w\") as file:\n",
        "#    file.write(html) \n",
        "#files.download('1_all_website.html')\n",
        "\n",
        "\n",
        "only_messages = re.search('<div id=\"topic\" >(.*?)<div class=\"bottom_action_topic_menu\">', html, re.MULTILINE | re.DOTALL).group(1)\n",
        "#with open(\"2_only_messages.html\", \"w\") as file:\n",
        "#     file.write(only_messages) \n",
        "#files.download('2_only_messages.html')\n",
        "\n",
        "messages_page = re.findall('class=\"md-topic_post(.*?)/table>', only_messages, re.MULTILINE | re.DOTALL)\n",
        "\n",
        "for message in messages_page:\n",
        "    if re.match('.*data-id_user.*', message, re.DOTALL):\n",
        "        user = re.search('data-id_user.+?>(.+?)<', message).group(1)\n",
        "    elif re.match('.*itemprop=\"name\"', message, re.DOTALL):\n",
        "        user = re.search('itemprop=\"name\".*?>(.+?)<', message).group(1) #parfois hidden est rajouté dans le code source donc .+? après name\n",
        "    elif re.match('.*Profil supprimé.*', message, re.DOTALL):\n",
        "        user = \"Profil supprimé\"\n",
        "    else:\n",
        "        user = \"[ERROR_Encodage_user_unknown]\"\n",
        "    date = re.search('Posté le ([0-9/]+)', message).group(1)\n",
        "    if re.match('.*itemprop=\"citation\".*', message, re.DOTALL):\n",
        "        message = re.sub('itemprop=\"citation\".+?</span></span>', '', message, re.MULTILINE | re.DOTALL)\n",
        "    text = re.search('itemprop=\"text\" hidden>(.*?)</span>[<div>|<span itemprop=\"author\"]', message, re.MULTILINE | re.DOTALL).group(1)\n",
        "    text = clean_message(text)\n",
        "    df = df.append({'date':date, 'user':user, 'text':text, 'url':url}, ignore_index=True)\n",
        "\n",
        "print(str(len(messages_page)))\n",
        "df\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ici\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [date, user, text, url]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}